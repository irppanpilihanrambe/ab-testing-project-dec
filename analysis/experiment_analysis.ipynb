{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using RAW PATH: /Users/irpanpilihanrambe/Downloads/DATA SET PROJECT DEC/raw\n",
      "Running: Menu Design\n",
      "Running: Novelty Slider\n",
      "Running: Product Sliders\n",
      "Running: Reviews Experiment\n",
      "Running: Search Engine\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>metric</th>\n",
       "      <th>comparison</th>\n",
       "      <th>lift_%</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Menu Design</td>\n",
       "      <td>added_to_cart</td>\n",
       "      <td>B_dropdown_menu vs A_horizontal_menu</td>\n",
       "      <td>-10.34</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novelty Slider</td>\n",
       "      <td>products_added_from_novelties</td>\n",
       "      <td>B_personalized_novelties vs A_manual_novelties</td>\n",
       "      <td>283.33</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product Sliders</td>\n",
       "      <td>add_to_cart_rate</td>\n",
       "      <td>B_similar_products_top vs A_selected_by_others...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product Sliders</td>\n",
       "      <td>add_to_cart_rate</td>\n",
       "      <td>C_selected_by_others_top vs A_selected_by_othe...</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>0.89666</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reviews Experiment</td>\n",
       "      <td>converted</td>\n",
       "      <td>B_featured_reviews vs A_no_featured_reviews</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.77639</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Search Engine</td>\n",
       "      <td>converted</td>\n",
       "      <td>B_algolia_search vs A_hybris_search</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.37115</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           experiment                         metric  \\\n",
       "0         Menu Design                  added_to_cart   \n",
       "1      Novelty Slider  products_added_from_novelties   \n",
       "2     Product Sliders               add_to_cart_rate   \n",
       "3     Product Sliders               add_to_cart_rate   \n",
       "4  Reviews Experiment                      converted   \n",
       "5       Search Engine                      converted   \n",
       "\n",
       "                                          comparison  lift_%   pvalue  \\\n",
       "0               B_dropdown_menu vs A_horizontal_menu  -10.34  0.00000   \n",
       "1     B_personalized_novelties vs A_manual_novelties  283.33  0.00001   \n",
       "2  B_similar_products_top vs A_selected_by_others...    0.00  1.00000   \n",
       "3  C_selected_by_others_top vs A_selected_by_othe...   -1.64  0.89666   \n",
       "4        B_featured_reviews vs A_no_featured_reviews    0.80  0.77639   \n",
       "5                B_algolia_search vs A_hybris_search    4.93  0.37115   \n",
       "\n",
       "   significant  \n",
       "0         True  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "5        False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# FINAL AB TEST FRAMEWORK (PATH SAFE VERSION)\n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# ------------------------------------------\n",
    "# AUTO-DETECT RAW FOLDER\n",
    "# ------------------------------------------\n",
    "\n",
    "def find_raw_path():\n",
    "    current = os.getcwd()\n",
    "    \n",
    "    # If raw folder exists here\n",
    "    if os.path.exists(os.path.join(current, \"raw\")):\n",
    "        return os.path.join(current, \"raw\")\n",
    "    \n",
    "    # If raw folder exists one level up\n",
    "    parent = os.path.dirname(current)\n",
    "    if os.path.exists(os.path.join(parent, \"raw\")):\n",
    "        return os.path.join(parent, \"raw\")\n",
    "    \n",
    "    raise FileNotFoundError(\"Cannot find 'raw' folder.\")\n",
    "\n",
    "RAW_PATH = find_raw_path()\n",
    "print(\"Using RAW PATH:\", RAW_PATH)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# AB TEST FRAMEWORK\n",
    "# ==========================================\n",
    "\n",
    "class ABTestFramework:\n",
    "    \n",
    "    def __init__(self, alpha=0.05):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def proportion_test(self, g1, g2):\n",
    "        n1, n2 = len(g1), len(g2)\n",
    "        if n1 == 0 or n2 == 0:\n",
    "            return 0, 1.0\n",
    "        \n",
    "        s1, s2 = g1.sum(), g2.sum()\n",
    "        p1, p2 = s1/n1, s2/n2\n",
    "        \n",
    "        p_pool = (s1 + s2) / (n1 + n2)\n",
    "        se = np.sqrt(p_pool * (1 - p_pool) * (1/n1 + 1/n2))\n",
    "        \n",
    "        if se == 0:\n",
    "            return 0, 1.0\n",
    "        \n",
    "        z = (p2 - p1) / se\n",
    "        pvalue = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "        \n",
    "        lift = ((p2 - p1) / p1 * 100) if p1 != 0 else 0\n",
    "        return lift, pvalue\n",
    "\n",
    "    def t_test(self, g1, g2):\n",
    "        if len(g1) == 0 or len(g2) == 0:\n",
    "            return 0, 1.0\n",
    "        \n",
    "        stat, pvalue = stats.ttest_ind(g2, g1, equal_var=False)\n",
    "        mean1, mean2 = g1.mean(), g2.mean()\n",
    "        \n",
    "        lift = ((mean2 - mean1) / mean1 * 100) if mean1 != 0 else 0\n",
    "        return lift, pvalue\n",
    "\n",
    "    def run_test(self, df, variant_col, metric_col):\n",
    "        variants = df[variant_col].value_counts().index.tolist()\n",
    "        \n",
    "        if len(variants) < 2:\n",
    "            raise ValueError(\"Not enough variant groups.\")\n",
    "        \n",
    "        baseline = variants[0]\n",
    "        results = []\n",
    "        \n",
    "        for variant in variants[1:]:\n",
    "            g1 = df[df[variant_col] == baseline][metric_col].dropna()\n",
    "            g2 = df[df[variant_col] == variant][metric_col].dropna()\n",
    "            \n",
    "            unique_vals = set(df[metric_col].dropna().unique())\n",
    "            \n",
    "            if unique_vals.issubset({0,1}):\n",
    "                lift, pvalue = self.proportion_test(g1, g2)\n",
    "            else:\n",
    "                lift, pvalue = self.t_test(g1, g2)\n",
    "            \n",
    "            results.append({\n",
    "                \"comparison\": f\"{variant} vs {baseline}\",\n",
    "                \"lift_%\": round(lift, 2),\n",
    "                \"pvalue\": round(pvalue, 5),\n",
    "                \"significant\": pvalue < self.alpha\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# EXPERIMENT CONFIG\n",
    "# ==========================================\n",
    "\n",
    "EXPERIMENT_CONFIG = {\n",
    "    \"Menu Design\": (\"test1_menu.csv\", \"added_to_cart\"),\n",
    "    \"Novelty Slider\": (\"test2_novelty_slider.csv\", \"products_added_from_novelties\"),\n",
    "    \"Product Sliders\": (\"test3_product_sliders.csv\", \"add_to_cart_rate\"),\n",
    "    \"Reviews Experiment\": (\"test4_reviews.csv\", \"converted\"),\n",
    "    \"Search Engine\": (\"test5_search_engine.csv\", \"converted\"),\n",
    "}\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# RUN ALL\n",
    "# ==========================================\n",
    "\n",
    "framework = ABTestFramework()\n",
    "results = []\n",
    "\n",
    "for name, (file, metric) in EXPERIMENT_CONFIG.items():\n",
    "    \n",
    "    print(\"Running:\", name)\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(RAW_PATH, file))\n",
    "    \n",
    "    test_results = framework.run_test(\n",
    "        df,\n",
    "        variant_col=\"variant\",\n",
    "        metric_col=metric\n",
    "    )\n",
    "    \n",
    "    for res in test_results:\n",
    "        results.append({\n",
    "            \"experiment\": name,\n",
    "            \"metric\": metric,\n",
    "            \"comparison\": res[\"comparison\"],\n",
    "            \"lift_%\": res[\"lift_%\"],\n",
    "            \"pvalue\": res[\"pvalue\"],\n",
    "            \"significant\": res[\"significant\"]\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
